{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19C/AgnesG Kopie.txt',\n",
       " '19C/alice Kopie.txt',\n",
       " '19C/alli Kopie.txt',\n",
       " '19C/alone Kopie.txt',\n",
       " '19C/americannotes Kopie.txt',\n",
       " '19C/amulet Kopie.txt',\n",
       " '19C/Antoni Kopie.txt',\n",
       " '19C/arma Kopie.txt',\n",
       " '19C/awakening Kopie.txt',\n",
       " '19C/basker Kopie.txt',\n",
       " '19C/beauty Kopie.txt',\n",
       " '19C/brass Kopie.txt',\n",
       " '19C/bunny Kopie.txt',\n",
       " '19C/canada Kopie.txt',\n",
       " '19C/carol Kopie.txt',\n",
       " '19C/carved Kopie.txt',\n",
       " '19C/clive Kopie.txt',\n",
       " '19C/coral Kopie.txt',\n",
       " '19C/cran Kopie.txt',\n",
       " '19C/crofton Kopie.txt',\n",
       " '19C/cuckoo Kopie.txt',\n",
       " '19C/daisy Kopie.txt',\n",
       " '19C/Deronda Kopie.txt',\n",
       " '19C/dominics Kopie.txt',\n",
       " '19C/dorian Kopie.txt',\n",
       " '19C/dove Kopie.txt',\n",
       " '19C/dracula Kopie.txt',\n",
       " '19C/dragons Kopie.txt',\n",
       " '19C/dreamdays Kopie.txt',\n",
       " '19C/duke Kopie.txt',\n",
       " '19C/emma Kopie.txt',\n",
       " '19C/eric Kopie.txt',\n",
       " '19C/fiord Kopie.txt',\n",
       " '19C/five Kopie.txt',\n",
       " '19C/flopsy Kopie.txt',\n",
       " '19C/forest Kopie.txt',\n",
       " '19C/frank Kopie.txt',\n",
       " '19C/girls Kopie.txt',\n",
       " '19C/glass Kopie.txt',\n",
       " '19C/goldenage Kopie.txt',\n",
       " '19C/gulliver Kopie.txt',\n",
       " '19C/heart Kopie.txt',\n",
       " '19C/holiday Kopie.txt',\n",
       " '19C/howwhy Kopie.txt',\n",
       " '19C/HT Kopie.txt',\n",
       " '19C/huckleberry Kopie.txt',\n",
       " '19C/jackanapes Kopie.txt',\n",
       " '19C/jane Kopie.txt',\n",
       " '19C/Jekyll Kopie.txt',\n",
       " '19C/jemima Kopie.txt',\n",
       " '19C/jessica Kopie.txt',\n",
       " '19C/Jude Kopie.txt',\n",
       " '19C/jungle Kopie.txt',\n",
       " '19C/kidnap Kopie.txt',\n",
       " '19C/LadyAud Kopie.txt',\n",
       " '19C/ladysusan Kopie.txt',\n",
       " '19C/LD Kopie.txt',\n",
       " '19C/leila Kopie.txt',\n",
       " '19C/maisie Kopie.txt',\n",
       " '19C/mansfield Kopie.txt',\n",
       " '19C/mary Kopie.txt',\n",
       " '19C/masterman Kopie.txt',\n",
       " '19C/MC Kopie.txt',\n",
       " '19C/meg Kopie.txt',\n",
       " '19C/mice Kopie.txt',\n",
       " '19C/middlemarch Kopie.txt',\n",
       " '19C/mill Kopie.txt',\n",
       " '19C/moonfleet Kopie.txt',\n",
       " '19C/moonstone Kopie.txt',\n",
       " '19C/mopsa Kopie.txt',\n",
       " '19C/mulgars Kopie.txt',\n",
       " '19C/native Kopie.txt',\n",
       " '19C/NN Kopie.txt',\n",
       " '19C/northanger Kopie.txt',\n",
       " '19C/NorthS Kopie.txt',\n",
       " '19C/OCS Kopie.txt',\n",
       " '19C/OMF Kopie.txt',\n",
       " '19C/OT Kopie.txt',\n",
       " '19C/overtheway Kopie.txt',\n",
       " '19C/pan Kopie.txt',\n",
       " '19C/peasant Kopie.txt',\n",
       " '19C/persuasion Kopie.txt',\n",
       " '19C/pictures Kopie.txt',\n",
       " '19C/Pomp Kopie.txt',\n",
       " '19C/portraitone Kopie.txt',\n",
       " '19C/portraittwo Kopie.txt',\n",
       " '19C/PP Kopie.txt',\n",
       " '19C/pride Kopie.txt',\n",
       " '19C/prigio Kopie.txt',\n",
       " '19C/prince Kopie.txt',\n",
       " '19C/princess Kopie.txt',\n",
       " '19C/Prof Kopie.txt',\n",
       " '19C/quatermain Kopie.txt',\n",
       " '19C/rabbit Kopie.txt',\n",
       " '19C/railway Kopie.txt',\n",
       " '19C/redclyffe Kopie.txt',\n",
       " '19C/rival Kopie.txt',\n",
       " '19C/room Kopie.txt',\n",
       " '19C/rose Kopie.txt',\n",
       " '19C/secret Kopie.txt',\n",
       " '19C/seekers Kopie.txt',\n",
       " '19C/sense Kopie.txt',\n",
       " '19C/settlers Kopie.txt',\n",
       " '19C/shirley Kopie.txt',\n",
       " '19C/signfour Kopie.txt',\n",
       " '19C/silas Kopie.txt',\n",
       " '19C/sketches Kopie.txt',\n",
       " '19C/soldier Kopie.txt',\n",
       " '19C/solomons Kopie.txt',\n",
       " '19C/squirrel Kopie.txt',\n",
       " '19C/stalky Kopie.txt',\n",
       " '19C/stiria Kopie.txt',\n",
       " '19C/sybil Kopie.txt',\n",
       " '19C/tapestry Kopie.txt',\n",
       " '19C/tenant Kopie.txt',\n",
       " '19C/Tess Kopie.txt',\n",
       " '19C/thejungle Kopie.txt',\n",
       " '19C/timemachine Kopie.txt',\n",
       " '19C/toadylion Kopie.txt',\n",
       " '19C/tombrown Kopie.txt',\n",
       " '19C/treasure Kopie.txt',\n",
       " '19C/TTC Kopie.txt',\n",
       " '19C/twelveyears Kopie.txt',\n",
       " '19C/uncommercial Kopie.txt',\n",
       " '19C/unlikely Kopie.txt',\n",
       " '19C/vanity Kopie.txt',\n",
       " '19C/vice Kopie.txt',\n",
       " '19C/villette Kopie.txt',\n",
       " '19C/VivianG Kopie.txt',\n",
       " '19C/wallypug Kopie.txt',\n",
       " '19C/war Kopie.txt',\n",
       " '19C/water Kopie.txt',\n",
       " '19C/wh Kopie.txt',\n",
       " '19C/willows Kopie.txt',\n",
       " '19C/wind Kopie.txt',\n",
       " '19C/winning Kopie.txt',\n",
       " '19C/womenlove Kopie.txt',\n",
       " '19C/woodmagic Kopie.txt',\n",
       " '19C/wwhite Kopie.txt',\n",
       " '19C/yellow Kopie.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textfiles = glob.glob(\"19C/*txt\") # list files in local directory  \n",
    "textfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textList=[]\n",
    "for textFile in textfiles: # create a list \n",
    "    f = open(textFile, \"r\")\n",
    "    textList = textList + [f.read().upper()]\n",
    "    f.close()\n",
    "len(textList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80942448"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "novelsString=\"\"\n",
    "for text in textList:\n",
    "    novelsString = novelsString +\"\\n\"+text\n",
    "len(novelsString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple lowercase tokenize\n",
    "novelsTokensLowercase = nltk.word_tokenize(novelsString.lower())\n",
    "\n",
    "# filter out tokens that aren't words\n",
    "novelsWordTokensLowercase = [word for word in novelsTokensLowercase if word[0].isalpha()]\n",
    "\n",
    "# determine frequencies\n",
    "novelsWordTokensLowercaseFreqs = nltk.FreqDist(novelsWordTokensLowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "novelsRealContentWordTokensLowercase = [word for word in novelsWordTokensLowercase \\\n",
    "        if word[0].isalpha() and word not in stopwords]\n",
    "novelsRealContentWordFrequencies = nltk.FreqDist(novelsRealContentWordTokensLowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cee171826fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_text_for_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.99\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-bcd7a37e9195>\u001b[0m in \u001b[0;36mprepare_text_for_lda\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_text_for_lda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0men_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mget_lemma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenize' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "textList=[]\n",
    "for textFile in textfiles: # create a list \n",
    "    f = open(textFile, \"r\")\n",
    "    for line in f:\n",
    "        tokens = prepare_text_for_lda(line)\n",
    "        if random.random() > .99:\n",
    "            print(tokens)\n",
    "            textList.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
